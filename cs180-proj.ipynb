{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fcb4f3f5-52ea-4d9d-a3e0-1429f0d78be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import os\n",
    "\n",
    "# for showing the image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# for testing like opening an image\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c7c976d1-ed1e-4a7a-a584-850fbfccb2c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.DS_Store', 'healthy', 'cordana', 'pestalotiopsis', 'sigatoka']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('./train/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2d3c7519-fce1-4113-b392-8b064d1888d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training dataset path\n",
    "training_dataset_path = './train/'\n",
    "# path to each dataset\n",
    "healthy_banana_dataset_path = './train/healthy/'\n",
    "cordona_banana_dataset_path = './train/cordana/'\n",
    "pestalotiopsis_banana_dataset_path = './train/pestalotiopsis/'\n",
    "sigatoka_banana_dataset_path = './train/sigatoka/'"
   ]
  },
  {
   "cell_type": "raw",
   "id": "029dc14a-2d15-4b40-9c18-a7490c3f0a32",
   "metadata": {},
   "source": [
    "Reference: https://pytorch.org/tutorials/beginner/data_loading_tutorial.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608527f9-2538-4fdc-8fdb-63c0cb69be30",
   "metadata": {},
   "source": [
    "# Find mean and std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1f31d7dd-ed7d-4088-92a0-4d7192d009a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_transforms = transforms.Compose([transforms.ToTensor()]) # convert images to pytorch tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7f989b91-a45a-4df3-84a3-9935f4ed14bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torchvision.datasets.ImageFolder(root=training_dataset_path, transform=training_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1b8d9d30-007c-4312-97a7-b4f504816397",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a606eea1-e84b-40a5-8a3e-96cf71a2e011",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_and_std(loader):\n",
    "    mean = 0\n",
    "    std = 0\n",
    "    total_images = 0\n",
    "\n",
    "    for images, _ in loader:\n",
    "        images_per_batch = images.size(0)\n",
    "        # print(images.shape) \n",
    "        images = images.view(images_per_batch, images.size(1), -1) # reshape image\n",
    "        # print(images.shape)\n",
    "        mean += images.mean(2).sum(0)\n",
    "        std += images.std(2).sum(0)\n",
    "        total_images += images_per_batch\n",
    "\n",
    "    mean /= total_images \n",
    "    std /= total_images\n",
    "\n",
    "    # approx mean and std not actual precise mean and std\n",
    "    return mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b8773e9b-a125-4073-8828-c8c4fab712a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5285, 0.5606, 0.3673]) tensor([0.1232, 0.1068, 0.1230])\n"
     ]
    }
   ],
   "source": [
    "mean, std = get_mean_and_std(train_loader)\n",
    "print(mean, std)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1645c2-00cc-4e72-a7b1-e996a5ddb3ab",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd59bd1f-b572-453a-874d-6ca27165caab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Transformation\n",
    "# no need to resize! already resized to 224 x 224 px\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(), # convert images to pytorch tensors\n",
    "    # transforms.Normalize(mean=[mean_R, mean_G, mean_B], std=[std_R, std_G, std_B])\n",
    "    transforms.normalize(torch.Tensor(mean), torch.Tensor(std)) \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746ecf5c-c814-4d89-b0a7-d15601674b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BananaDataset(Dataset):\n",
    "    def __init__(self, data_dir transform=None):\n",
    "        self.data_dir = data_dir\n",
    "        self.transform = transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ceb0ecf-22fc-4573-b232-84b8215eca78",
   "metadata": {},
   "outputs": [],
   "source": [
    "healthy_data = BananaDataset(data_dir=healthy_banana_dataset_path, transforms)\n",
    "cordona_data = BananaDataset(data_dir=cordona_banana_dataset_path, transforms)\n",
    "pestalotiopsis_data = BananaDataset(data_dir=pestalotiopsis_banana_dataset_path, transforms)\n",
    "sigatoka_data = BananaDataset(data_dir=psigatoka_banana_dataset_path, transforms)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
